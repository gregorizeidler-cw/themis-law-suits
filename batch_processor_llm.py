# üì¶ #### Batch Processor com LLM - An√°lise Inteligente de Absolvi√ß√£o em Lote
import os
import re
import json
import time
import threading
from typing import List, Dict, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import pandas as pd
import requests
import openai
from dotenv import load_dotenv

# Carregar vari√°veis de ambiente
load_dotenv()

# üîê #### Credenciais
bigdata_token_id = os.getenv('BIGDATA_TOKEN_ID')
bigdata_token_hash = os.getenv('BIGDATA_TOKEN_HASH')
openai_api_key = os.getenv('OPENAI_API_KEY')

class BatchAbsolutionAnalyzerLLM:
    """Analisador de absolvi√ß√µes em lote com IA para m√∫ltiplos CPFs"""
    
    def __init__(self, max_workers: int = 5, delay_between_requests: float = 0.3):
        self.max_workers = max_workers  # Menos workers para n√£o sobrecarregar a OpenAI
        self.delay_between_requests = delay_between_requests
        
        # Verificar credenciais BigData
        if not bigdata_token_id or not bigdata_token_hash:
            raise ValueError("Credenciais BigData Corp n√£o configuradas no arquivo .env")
        
        # Verificar credenciais OpenAI
        if not openai_api_key:
            raise ValueError("OPENAI_API_KEY n√£o configurada no arquivo .env")
        
        self.openai_client = openai.OpenAI(api_key=openai_api_key)
        print("‚úÖ LLM (OpenAI GPT-4) inicializada com sucesso!")
    
    def fetch_single_cpf_data(self, cpf: str) -> Dict:
        """Buscar dados de um √∫nico CPF focando em processos criminais"""
        try:
            cpf_sanitizado = re.sub(r'\D', '', cpf)
            if len(cpf_sanitizado) != 11:
                return {"cpf": cpf, "error": "CPF inv√°lido"}
            
            # Adicionar delay para evitar rate limiting
            time.sleep(self.delay_between_requests)
            
            headers = {
                "Accept": "application/json",
                "Content-Type": "application/json",
                "AccessToken": bigdata_token_hash,
                "TokenId": bigdata_token_id
            }
            
            payload = {
                "q": f"doc{{{cpf_sanitizado}}}",
                "Datasets": """basic_data,
                               processes.filter(partypolarity = PASSIVE, courttype = CRIMINAL),
                               kyc.filter(standardized_type, standardized_sanction_type, type, sanctions_source = Conselho Nacional de Justi√ßa)"""
            }
            
            response = requests.post(
                "https://plataforma.bigdatacorp.com.br/pessoas",
                json=payload,
                headers=headers,
                timeout=30
            )
            
            response.raise_for_status()
            return response.json()
            
        except Exception as e:
            print(f"Erro ao processar CPF {cpf}: {str(e)}")
            return {"cpf": cpf, "error": str(e)}
    
    def analyze_with_llm(self, texto_decisoes: str, dados_pessoa: Dict) -> Dict:
        """Analisar decis√µes com IA (GPT-4) para determinar absolvi√ß√£o"""
        try:
            if not texto_decisoes.strip():
                return {
                    "foi_absolvido": None,
                    "confianca_analise": 0,
                    "justificativa": "Nenhuma decis√£o dispon√≠vel para an√°lise",
                    "detalhes_ia": "Sem dados suficientes"
                }
            
            prompt = f"""
Voc√™ √© um especialista jur√≠dico. Analise as decis√µes judiciais abaixo e determine se a pessoa foi ABSOLVIDA em processos criminais.

DADOS DA PESSOA:
Nome: {dados_pessoa.get('nome', 'N√£o informado')}
CPF: {dados_pessoa.get('cpf', 'N√£o informado')}

DECIS√ïES JUDICIAIS:
{texto_decisoes}

INSTRU√á√ÉO ESPEC√çFICA:
1. Determine se houve ABSOLVI√á√ÉO em algum processo criminal
2. Considere: absolvi√ß√µes, improced√™ncias, arquivamentos, extin√ß√µes
3. Ignore processos onde a pessoa n√£o seja r√©u/investigado
4. Seja preciso: s√≥ retorne True se houver absolvi√ß√£o clara

RESPONDA APENAS EM JSON:
{{
  "foi_absolvido": true/false/null,
  "confianca_analise": 0-100,
  "justificativa": "Explica√ß√£o clara da an√°lise",
  "detalhes_ia": "Resumo dos processos relevantes"
}}
"""
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um analista jur√≠dico especializado em an√°lise de absolvi√ß√µes. Responda sempre em JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.2,
                response_format={"type": "json_object"}
            )
            
            resultado_ia = json.loads(response.choices[0].message.content)
            return resultado_ia
            
        except Exception as e:
            return {
                "foi_absolvido": None,
                "confianca_analise": 0,
                "justificativa": f"Erro na an√°lise IA: {str(e)}",
                "detalhes_ia": "Falha no processamento"
            }
    
    def analyze_absolution_with_llm(self, bdc_data: Dict, cpf: str) -> Dict:
        """Analisar absolvi√ß√£o usando IA"""
        try:
            if "Result" not in bdc_data or not bdc_data["Result"]:
                return {
                    "cpf": cpf,
                    "nome": "N√£o encontrado",
                    "foi_absolvido": None,
                    "confianca_analise": 0,
                    "justificativa": "Dados n√£o encontrados na base",
                    "detalhes_ia": "CPF n√£o localizado",
                    "total_processos_criminais": 0,
                    "status": "dados_nao_encontrados"
                }
            
            pessoa = bdc_data["Result"][0]
            basic = pessoa.get("BasicData", {})
            nome = basic.get("Name", "Nome n√£o informado")
            
            processos = pessoa.get("Processes", {})
            lawsuits = processos.get("Lawsuits", [])
            
            # Filtrar apenas processos criminais onde a pessoa √© r√©
            processos_criminais = []
            texto_completo_decisoes = []
            
            for proc in lawsuits:
                if proc.get("CourtType") == "CRIMINAL":
                    # Verificar se √© r√©u
                    partes = proc.get("Parties", [])
                    is_reu = False
                    for parte in partes:
                        papel = parte.get("Type", "").upper()
                        nome_parte = parte.get("Name", "").strip().upper()
                        espec = parte.get("PartyDetails", {}).get("SpecificType", "").upper()
                        
                        if (papel == "DEFENDANT" or papel == "R√âU" or espec == "R√âU") and \
                           nome.strip().upper() in nome_parte:
                            is_reu = True
                            break
                    
                    if is_reu:
                        processos_criminais.append(proc)
                        
                        # Coletar dados do processo para IA
                        numero_processo = proc.get("CaseNumber") or proc.get("Number", "")
                        tribunal = proc.get("CourtName", "")
                        
                        # Coletar textos relevantes
                        textos_processo = []
                        
                        # Conte√∫do do processo
                        if proc.get("Content"):
                            textos_processo.append(f"Conte√∫do: {proc.get('Content')}")
                        
                        # Decis√£o principal
                        if proc.get("Decision"):
                            textos_processo.append(f"Decis√£o: {proc.get('Decision')}")
                        
                        # Descri√ß√£o
                        if proc.get("Description"):
                            textos_processo.append(f"Descri√ß√£o: {proc.get('Description')}")
                        
                        # Decis√µes espec√≠ficas
                        decisoes = proc.get("Decisions", [])
                        for i, decisao in enumerate(decisoes):
                            conteudo_decisao = decisao.get("DecisionContent", "")
                            data_decisao = decisao.get("DecisionDate", "")
                            if conteudo_decisao:
                                textos_processo.append(f"Decis√£o {i+1} ({data_decisao}): {conteudo_decisao}")
                        
                        # Consolidar texto do processo
                        if textos_processo:
                            texto_processo_completo = f"""
PROCESSO {numero_processo} - {tribunal}:
{chr(10).join(textos_processo)}
---
"""
                            texto_completo_decisoes.append(texto_processo_completo)
            
            total_processos = len(processos_criminais)
            
            # Analisar com IA
            texto_para_ia = "\n".join(texto_completo_decisoes)
            dados_pessoa = {"nome": nome, "cpf": cpf}
            
            resultado_ia = self.analyze_with_llm(texto_para_ia, dados_pessoa)
            
            return {
                "cpf": cpf,
                "nome": nome,
                "foi_absolvido": resultado_ia.get("foi_absolvido"),
                "confianca_analise": resultado_ia.get("confianca_analise", 0),
                "justificativa": resultado_ia.get("justificativa", ""),
                "detalhes_ia": resultado_ia.get("detalhes_ia", ""),
                "total_processos_criminais": total_processos,
                "status": "sucesso"
            }
            
        except Exception as e:
            return {
                "cpf": cpf,
                "nome": "Erro no processamento",
                "foi_absolvido": None,
                "confianca_analise": 0,
                "justificativa": f"Erro durante processamento: {str(e)}",
                "detalhes_ia": "Falha na an√°lise",
                "total_processos_criminais": 0,
                "status": f"erro: {str(e)}"
            }
    
    def process_batch(self, cpfs: List[str], progress_callback=None) -> List[Dict]:
        """Processar lista de CPFs em lote com an√°lise IA"""
        results = []
        total = len(cpfs)
        
        print(f"üß† Iniciando processamento INTELIGENTE em lote de {total} CPFs...")
        print("‚ö° Usando GPT-4 para an√°lise contextual das decis√µes")
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submeter todas as tarefas
            future_to_cpf = {executor.submit(self.fetch_single_cpf_data, cpf): cpf for cpf in cpfs}
            
            for i, future in enumerate(as_completed(future_to_cpf), 1):
                cpf = future_to_cpf[future]
                try:
                    bdc_data = future.result()
                    
                    # Analisar com IA
                    if "error" in bdc_data:
                        result = {
                            "cpf": cpf,
                            "nome": "Erro na consulta",
                            "foi_absolvido": None,
                            "confianca_analise": 0,
                            "justificativa": f"Erro na API: {bdc_data['error']}",
                            "detalhes_ia": "Falha na consulta de dados",
                            "total_processos_criminais": 0,
                            "status": f"erro_api: {bdc_data['error']}"
                        }
                    else:
                        result = self.analyze_absolution_with_llm(bdc_data, cpf)
                    
                    results.append(result)
                    
                    # Callback de progresso
                    if progress_callback:
                        progress_callback(i, total, result)
                    
                    # Log de progresso
                    if i % 5 == 0 or i == total:
                        print(f"ü§ñ Processados com IA: {i}/{total} CPFs ({i/total*100:.1f}%)")
                
                except Exception as exc:
                    print(f'CPF {cpf} gerou exce√ß√£o: {exc}')
                    results.append({
                        "cpf": cpf,
                        "nome": "Erro na consulta",
                        "foi_absolvido": None,
                        "confianca_analise": 0,
                        "justificativa": f"Exce√ß√£o durante processamento: {str(exc)}",
                        "detalhes_ia": "Falha no processamento",
                        "total_processos_criminais": 0,
                        "status": f"excecao: {str(exc)}"
                    })
        
        return results
    
    def export_to_csv(self, results: List[Dict], filename: str = "analise_absolvicoes_llm.csv"):
        """Exportar resultados para CSV com dados da IA"""
        # Dados para CSV com colunas extras da IA
        csv_data = []
        for result in results:
            csv_data.append({
                "CPF": result["cpf"],
                "Nome": result["nome"],
                "Foi_Absolvido": result["foi_absolvido"],
                "Confianca_Analise": result.get("confianca_analise", 0),
                "Justificativa_IA": result.get("justificativa", ""),
                "Detalhes_IA": result.get("detalhes_ia", ""),
                "Total_Processos_Criminais": result["total_processos_criminais"],
                "Status": result["status"]
            })
        
        df = pd.DataFrame(csv_data)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"Resultados da an√°lise IA exportados para: {filename}")
        return filename
    
    def get_summary_stats(self, results: List[Dict]) -> Dict:
        """Obter estat√≠sticas resumidas dos resultados com dados da IA"""
        total = len(results)
        absolvidos = sum(1 for r in results if r["foi_absolvido"] is True)
        nao_absolvidos = sum(1 for r in results if r["foi_absolvido"] is False)
        sem_dados = sum(1 for r in results if r["foi_absolvido"] is None)
        
        # Estat√≠sticas de confian√ßa da IA
        confiancas = [r.get("confianca_analise", 0) for r in results if r.get("confianca_analise") is not None]
        confianca_media = sum(confiancas) / len(confiancas) if confiancas else 0
        
        return {
            "total_processados": total,
            "total_absolvidos": absolvidos,
            "total_nao_absolvidos": nao_absolvidos,
            "total_sem_dados": sem_dados,
            "percentual_absolvidos": (absolvidos / total * 100) if total > 0 else 0,
            "percentual_nao_absolvidos": (nao_absolvidos / total * 100) if total > 0 else 0,
            "percentual_sem_dados": (sem_dados / total * 100) if total > 0 else 0,
            "confianca_media_ia": confianca_media,
            "analises_com_alta_confianca": sum(1 for c in confiancas if c >= 80),
            "analises_com_baixa_confianca": sum(1 for c in confiancas if c < 50)
        }

# Fun√ß√£o para teste
if __name__ == "__main__":
    # Teste com alguns CPFs de exemplo
    analyzer = BatchAbsolutionAnalyzerLLM(max_workers=2, delay_between_requests=0.5)
    
    cpfs_teste = [
        "01130380114",  # CPF de exemplo
        "12345678901",  # CPF inv√°lido para teste
    ]
    
    results = analyzer.process_batch(cpfs_teste)
    
    # Mostrar resultados
    for result in results:
        print(f"\nü§ñ AN√ÅLISE IA:")
        print(f"CPF: {result['cpf']}")
        print(f"Nome: {result['nome']}")
        print(f"Foi absolvido: {result['foi_absolvido']}")
        print(f"Confian√ßa: {result.get('confianca_analise', 0)}%")
        print(f"Justificativa: {result.get('justificativa', '')}")
        print(f"Detalhes IA: {result.get('detalhes_ia', '')}")
        print(f"Status: {result['status']}")
        print("-" * 70)
    
    # Estat√≠sticas
    stats = analyzer.get_summary_stats(results)
    print("\nüìä ESTAT√çSTICAS IA:")
    print(json.dumps(stats, indent=2, ensure_ascii=False))
    
    # Exportar para CSV
    analyzer.export_to_csv(results, "teste_absolvicoes_llm.csv")
